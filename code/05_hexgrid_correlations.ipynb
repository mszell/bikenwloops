{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e582dfd",
   "metadata": {},
   "source": [
    "# 05. Hex-grid correlations, Denmark-wide\n",
    "## Project: Bicycle node network loop analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc9b960",
   "metadata": {},
   "source": [
    "This notebook puts loop census and scenario data from 02 and 04 into an H3 grid and performs local spatial autocorrelation and pairwise correlations.  \n",
    "Please select `denmark` as the `study_area` in the `config.yml`.\n",
    "\n",
    "Contact: Michael Szell (michael.szell@gmail.com)\n",
    "\n",
    "Created: 2025-08-01  \n",
    "Last modified: 2025-08-12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816924f7-7ddc-44a1-bcd7-fbf203a41b1d",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb810d3b-192d-47d8-8d62-d699be65bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i setup_parameters.py\n",
    "load_data = True  # Set to False if data are huge and have already been loaded\n",
    "debug = False  # Set to True for extra plots and verbosity\n",
    "plt.style.use(PATH[\"parameters\"] + \"plotstyle.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ab0c20-4b70-4f78-acc8-df437f100b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:  # See if allloops_dict exists. If not, initialize. This allows running multiple scenarios.\n",
    "    allloops_dict\n",
    "except NameError:\n",
    "    allloops_dict = {}\n",
    "    dfunified_scenarios = {}\n",
    "allloops_dict[SCENARIOID] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b986890-413c-43c3-a6fa-57ff87899f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running scenario \" + str(SCENARIOID) + \" in \" + STUDY_AREA)\n",
    "for k, v in SCENARIO[SCENARIOID].items():\n",
    "    print(k + \": \" + str(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876e2b5b",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a407c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd4d066",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731b1fbd-6ce8-431d-a097-e8f13313da26",
   "metadata": {},
   "source": [
    "This can take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6ab763",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_data:\n",
    "    if LOOP_LENGTH_BOUND:\n",
    "        llb_string = \"_maxlength\" + str(LOOP_LENGTH_BOUND)\n",
    "    else:\n",
    "        llb_string = \"\"\n",
    "\n",
    "    with open(\n",
    "        PATH[\"data_out\"]\n",
    "        + \"loopcensus_\"\n",
    "        + str(LOOP_NUMNODE_BOUND)\n",
    "        + llb_string\n",
    "        + \".pkl\",\n",
    "        \"rb\",\n",
    "    ) as f:\n",
    "        allloops = pickle.load(f)\n",
    "        alllooplengths = pickle.load(f)\n",
    "        allloopnumnodes = pickle.load(f)\n",
    "        allloopmaxslopes = pickle.load(f)\n",
    "        Gnx = pickle.load(f)\n",
    "        LOOP_NUMNODE_BOUND = pickle.load(f)\n",
    "        nodes_id = pickle.load(f)\n",
    "        nodes_coords = pickle.load(f)\n",
    "        numloops = pickle.load(f)\n",
    "        faceloops = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf416d7-1583-4ab0-be0c-869669186190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gdf and igraph versions\n",
    "nodes, edges = momepy.nx_to_gdf(net=Gnx, points=True, lines=True)\n",
    "nodes.set_crs(epsg=25832, inplace=True)\n",
    "edges.set_crs(epsg=25832, inplace=True)\n",
    "G = ig.Graph.from_networkx(Gnx)\n",
    "G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce8dbb6-4a98-49f7-a326-05a14d1aa8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot network\n",
    "if debug:\n",
    "    plot_dk_gdf(\n",
    "        nodes,\n",
    "        edges,\n",
    "        scale=0.4,\n",
    "        vertex_size=get_vertex_size_constant(G.vcount()),\n",
    "        link_width=get_edgewidth_constant(G.ecount()),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedbbbd0",
   "metadata": {},
   "source": [
    "## Put into H3 grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c309ab9-6a31-4a3f-92ef-804599e00bc0",
   "metadata": {},
   "source": [
    "### Node density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c8dc2c-953f-481f-8e7b-10ec8538190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    nodes.plot.scatter(x=\"x\", y=\"y\", style=\".\", alpha=0.5, figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb40f4c-7b2a-4413-accb-94082e66ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_nodata = nodes.drop(\n",
    "    columns=[\"name\", \"_igraph_index\", \"x\", \"y\", \"nodeID\"]\n",
    ")  # drop all data\n",
    "nodes_nodata.to_crs(epsg=4326, inplace=True)  # reproject for H3\n",
    "if debug:\n",
    "    print(nodes_nodata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee9f2fd-0817-49e9-a48a-f6d102ff60f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodesh3 = nodes_nodata.assign(count=1).h3.geo_to_h3_aggregate(6)\n",
    "if debug:\n",
    "    print(nodesh3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335cba92-dd62-40d0-9e4f-c19d8991556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodesh3.plot(column=\"count\", figsize=(5, 5), legend=True)\n",
    "plt.title(\"Node density\")\n",
    "plt.gca().axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7867c771-5107-4488-9670-b8c08ababd40",
   "metadata": {},
   "source": [
    "### Edge properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec2d36a-5b79-4f33-a275-345f4ce2b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgesh3 = edges.to_crs(epsg=25832)  # do geometric operations on projected CRS\n",
    "edgesh3[\"geometry\"] = edgesh3.geometry.centroid\n",
    "edgesh3.to_crs(epsg=4326, inplace=True)  # project back for H3\n",
    "if debug:\n",
    "    print(edgesh3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b66e9c-a9dc-46f2-b25c-087b509f7068",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_length = edgesh3[[\"weight\", \"geometry\"]]\n",
    "edges_max_slope = edgesh3[[\"weight\", \"max_slope\", \"geometry\"]]\n",
    "edges_has_water = edgesh3[[\"weight\", \"has_water\", \"geometry\"]]\n",
    "edges_has_water[\"has_water\"] = edges_has_water[\"has_water\"].astype(\n",
    "    int\n",
    ")  # Turn True/False into 1/0\n",
    "edges_poi_diversity = edgesh3[[\"weight\", \"poi_diversity\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06672c5f-d86f-46d6-8266-c111433b8faf",
   "metadata": {},
   "source": [
    "Weighted means (by length):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6a41cf-30d7-4542-965c-e3711965bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/31521027/groupby-weighted-average-and-sum-in-pandas-dataframe\n",
    "wm = {\n",
    "    \"max_slope\": lambda x: np.average(x, weights=edges_max_slope.loc[x.index, \"weight\"])\n",
    "}\n",
    "edges_max_slope_wmh3 = edges_max_slope.h3.geo_to_h3_aggregate(6, wm)\n",
    "\n",
    "wm = {\n",
    "    \"has_water\": lambda x: np.average(x, weights=edges_has_water.loc[x.index, \"weight\"])\n",
    "}\n",
    "edges_has_water_wmh3 = edges_has_water.h3.geo_to_h3_aggregate(6, wm)\n",
    "\n",
    "wm = {\n",
    "    \"poi_diversity\": lambda x: np.average(\n",
    "        x, weights=edges_poi_diversity.loc[x.index, \"weight\"]\n",
    "    )\n",
    "}\n",
    "edges_poi_diversity_wmh3 = edges_poi_diversity.h3.geo_to_h3_aggregate(6, wm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff2a40-fb9b-443b-90ad-9409f00fc34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_max_slope_wmh3.plot(column=\"max_slope\", figsize=(5, 5), legend=True)\n",
    "plt.title(\"Maximum gradient (weighted)\")\n",
    "plt.gca().axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b104cd1-cca6-4e21-8579-49e58bcd19c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_has_water_wmh3.plot(column=\"has_water\", figsize=(5, 5), legend=True)\n",
    "plt.title(\"Has water (weighted)\")\n",
    "plt.gca().axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd25380-5bfd-497f-8c8b-9d3e4391a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_poi_diversity_wmh3.plot(column=\"poi_diversity\", figsize=(5, 5), legend=True)\n",
    "plt.title(\"POI diversity (weighted)\")\n",
    "plt.gca().axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31024bf3-e049-466e-9083-de1360ca29ed",
   "metadata": {},
   "source": [
    "Unweighted means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4142647e-6003-4626-b7d6-f92b22000d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_lengthh3 = edges_length.h3.geo_to_h3_aggregate(6, \"mean\")\n",
    "edges_max_slopeh3 = edges_max_slope.h3.geo_to_h3_aggregate(\n",
    "    6, \"mean\"\n",
    ")  # not weighted by length\n",
    "edges_has_waterh3 = edges_has_water.h3.geo_to_h3_aggregate(\n",
    "    6, \"mean\"\n",
    ")  # not weighted by length\n",
    "edges_poi_diversityh3 = edges_poi_diversity.h3.geo_to_h3_aggregate(\n",
    "    6, \"mean\"\n",
    ")  # not weighted by length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6c008c-601c-4b9e-8ea1-7dae70ea403a",
   "metadata": {},
   "source": [
    "## LISA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9bc2ee-050e-4c39-9340-2339032dc80c",
   "metadata": {},
   "source": [
    "### Node density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98406b80-bb28-43f9-b78a-e13dc6026941",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodesh3.to_crs(epsg=25832, inplace=True)\n",
    "w = weights.contiguity.Queen.from_dataframe(nodesh3, use_index=False)\n",
    "if debug:\n",
    "    plot_spatial_weights(w, nodesh3)\n",
    "lisa = esda.Moran_Local(nodesh3[\"count\"], w)\n",
    "if debug:\n",
    "    plot_local_autocorrelation(lisa, nodesh3, \"count\")\n",
    "lisa_cluster(lisa, nodesh3, p=0.05)\n",
    "nodesh3.to_crs(epsg=4326, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e875836-4f32-4deb-a0db-254ba1053c70",
   "metadata": {},
   "source": [
    "### Maximum gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c787a81-4d8b-43ed-ac70-d0af963b91af",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_max_slope_wmh3.to_crs(epsg=25832, inplace=True)\n",
    "w = weights.contiguity.Queen.from_dataframe(edges_max_slope_wmh3, use_index=False)\n",
    "if debug:\n",
    "    plot_spatial_weights(w, edges_max_slope_wmh3)\n",
    "lisa = esda.Moran_Local(edges_max_slope_wmh3[\"max_slope\"], w)\n",
    "if debug:\n",
    "    plot_local_autocorrelation(lisa, edges_max_slope_wmh3, \"max_slope\")\n",
    "lisa_cluster(lisa, edges_max_slope_wmh3, p=0.05)\n",
    "edges_max_slope_wmh3.to_crs(epsg=4326, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415e313f-9d36-402b-bad8-87e76ea3b4d4",
   "metadata": {},
   "source": [
    "### Water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843c22c3-7e05-4169-9dea-cb65b19f7520",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_has_water_wmh3.to_crs(epsg=25832, inplace=True)\n",
    "w = weights.contiguity.Queen.from_dataframe(edges_has_water_wmh3, use_index=False)\n",
    "if debug:\n",
    "    plot_spatial_weights(w, edges_has_water_wmh3)\n",
    "lisa = esda.Moran_Local(edges_has_water_wmh3[\"has_water\"], w)\n",
    "if debug:\n",
    "    plot_local_autocorrelation(lisa, edges_has_water_wmh3, \"has_water\")\n",
    "lisa_cluster(lisa, edges_has_water_wmh3, p=0.05)\n",
    "edges_has_water_wmh3.to_crs(epsg=4326, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c02936f-6303-45f3-bc94-db79665fe8d6",
   "metadata": {},
   "source": [
    "### POI diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ef9672-903a-4be0-b278-c692b3bd3fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_poi_diversity_wmh3.to_crs(epsg=25832, inplace=True)\n",
    "w = weights.contiguity.Queen.from_dataframe(edges_poi_diversity_wmh3, use_index=False)\n",
    "if debug:\n",
    "    plot_spatial_weights(w, edges_poi_diversity_wmh3)\n",
    "lisa = esda.Moran_Local(edges_poi_diversity_wmh3[\"poi_diversity\"], w)\n",
    "if debug:\n",
    "    plot_local_autocorrelation(lisa, edges_poi_diversity_wmh3, \"poi_diversity\")\n",
    "lisa_cluster(lisa, edges_poi_diversity_wmh3, p=0.05)\n",
    "edges_poi_diversity_wmh3.to_crs(epsg=4326, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a60dd82-1770-4edc-910f-3d98e47385e1",
   "metadata": {},
   "source": [
    "## Loop census"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b10bcb-f070-490e-bfe2-9fd34b713cb1",
   "metadata": {},
   "source": [
    "### Restrict to scenario lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1593b251-e668-4a89-9495-db32f9d60126",
   "metadata": {},
   "outputs": [],
   "source": [
    "allloops_dict[SCENARIOID][0] = restrict_scenario(allloops, allloops, level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b63d62b-ec42-4c13-9627-5723922ec16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_loopnum1 = nodes.drop(\n",
    "    columns=[\"name\", \"_igraph_index\", \"x\", \"y\", \"nodeID\"]\n",
    ")  # drop all data\n",
    "nodes_loopnum1.to_crs(epsg=4326, inplace=True)  # reproject for H3\n",
    "nodes_loopnum1[\"loopnum1\"] = get_vertex_loopnums(\n",
    "    allloops_dict[SCENARIOID][0], \"log2\"\n",
    ").tolist()\n",
    "if debug:\n",
    "    print(nodes_loopnum1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe18209-408b-46b7-afa7-c3f540130cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_loopnum1h3 = nodes_loopnum1.h3.geo_to_h3_aggregate(6, \"mean\")\n",
    "if debug:\n",
    "    print(nodes_loopnum1h3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc27857-10ca-4e66-b411-8ef5400d66ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_loopnum1h3.plot(column=\"loopnum1\", figsize=(5, 5), legend=True)\n",
    "plt.title(\"Average loop bits (length restriction)\")\n",
    "plt.gca().axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888b1702-daa1-424c-94f0-681423ebe418",
   "metadata": {},
   "source": [
    "### Restrict to scenario gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbac3605-b5f1-439b-bad1-519e262dd53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "allloops_dict[SCENARIOID][1] = restrict_scenario(\n",
    "    allloops, allloops_dict[SCENARIOID][0], level=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384edba2-49ab-460d-86e6-20a7ceba2d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_loopnum2 = nodes.drop(\n",
    "    columns=[\"name\", \"_igraph_index\", \"x\", \"y\", \"nodeID\"]\n",
    ")  # drop all data\n",
    "nodes_loopnum2.to_crs(epsg=4326, inplace=True)  # reproject for H3\n",
    "nodes_loopnum2[\"loopnum2\"] = get_vertex_loopnums(\n",
    "    allloops_dict[SCENARIOID][1], \"log2\"\n",
    ").tolist()\n",
    "if debug:\n",
    "    print(nodes_loopnum2.head())\n",
    "\n",
    "nodes_loopnum2h3 = nodes_loopnum2.h3.geo_to_h3_aggregate(6, \"mean\")\n",
    "nodes_loopnum2h3.plot(column=\"loopnum2\", figsize=(5, 5), legend=True)\n",
    "plt.title(\"Average loop bits (gradient restriction)\")\n",
    "plt.gca().axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d22de8c-385c-4ae0-a16f-adb7db7bfc62",
   "metadata": {},
   "source": [
    "### Restrict to water limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552ac18d-dc23-469b-8b91-b74f5a10df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "allloops_dict[SCENARIOID][2] = restrict_scenario(\n",
    "    allloops, allloops_dict[SCENARIOID][1], level=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0174eefb-f75e-4343-bb63-297c6cd22bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_loopnum3 = nodes.drop(\n",
    "    columns=[\"name\", \"_igraph_index\", \"x\", \"y\", \"nodeID\"]\n",
    ")  # drop all data\n",
    "nodes_loopnum3.to_crs(epsg=4326, inplace=True)  # reproject for H3\n",
    "nodes_loopnum3[\"loopnum3\"] = get_vertex_loopnums(\n",
    "    allloops_dict[SCENARIOID][2], \"log2\"\n",
    ").tolist()\n",
    "if debug:\n",
    "    print(nodes_loopnum3.head())\n",
    "\n",
    "nodes_loopnum3h3 = nodes_loopnum3.h3.geo_to_h3_aggregate(6, \"mean\")\n",
    "nodes_loopnum3h3.plot(column=\"loopnum3\", figsize=(5, 5), legend=True)\n",
    "plt.title(\"Average loop bits (water restriction)\")\n",
    "plt.gca().axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2142bee4-92ac-4ed1-9bfa-44cd61e05231",
   "metadata": {},
   "source": [
    "### Restrict with POI diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0bbc90-ec31-4098-ab71-1dde8ef84a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "allloops_dict[SCENARIOID][3] = restrict_scenario(\n",
    "    allloops, allloops_dict[SCENARIOID][2], level=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef989b7-61ad-4a3e-a03a-fd5d96a467bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_loopnum4 = nodes.drop(\n",
    "    columns=[\"name\", \"_igraph_index\", \"x\", \"y\", \"nodeID\"]\n",
    ")  # drop all data\n",
    "nodes_loopnum4.to_crs(epsg=4326, inplace=True)  # reproject for H3\n",
    "nodes_loopnum4[\"loopnum4\"] = get_vertex_loopnums(\n",
    "    allloops_dict[SCENARIOID][3], \"log2\"\n",
    ").tolist()\n",
    "if debug:\n",
    "    print(nodes_loopnum4.head())\n",
    "\n",
    "nodes_loopnum4h3 = nodes_loopnum4.h3.geo_to_h3_aggregate(6, \"mean\")\n",
    "nodes_loopnum4h3.plot(column=\"loopnum4\", figsize=(5, 5), legend=True)\n",
    "plt.title(\"Average loop bits (POI restriction)\")\n",
    "plt.gca().axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bca00f6-0fb5-41e2-b512-245af5f0ccaa",
   "metadata": {},
   "source": [
    "## Correlate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d78bbe-d25f-43b7-9c57-acd364fad559",
   "metadata": {},
   "source": [
    "### Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d747fd9f-2f6b-4cb9-9171-db349a4483e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfunified_scenarios[SCENARIOID] = (\n",
    "    nodesh3.join(nodes_loopnum1h3.drop(columns=\"geometry\"))\n",
    "    .join(nodes_loopnum2h3.drop(columns=\"geometry\"))\n",
    "    .join(nodes_loopnum3h3.drop(columns=\"geometry\"))\n",
    "    .join(nodes_loopnum4h3.drop(columns=\"geometry\"))\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"count\": \"Node density\",\n",
    "            \"loopnum1\": \"Loop bits (length)\",\n",
    "            \"loopnum2\": \"Loop bits (gradient)\",\n",
    "            \"loopnum3\": \"Loop bits (water)\",\n",
    "            \"loopnum4\": \"Loop bits (POI)\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "pd.plotting.scatter_matrix(\n",
    "    dfunified_scenarios[SCENARIOID], alpha=0.05, figsize=(10, 10)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fe4732-8977-41db-a024-692300e66619",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(14, 3))\n",
    "\n",
    "xs = [\n",
    "    dfunified_scenarios[SCENARIOID][\"Loop bits (length)\"],\n",
    "    dfunified_scenarios[SCENARIOID][\"Loop bits (gradient)\"],\n",
    "    dfunified_scenarios[SCENARIOID][\"Loop bits (water)\"],\n",
    "    dfunified_scenarios[SCENARIOID][\"Loop bits (POI)\"],\n",
    "]\n",
    "xlabels = [\"length\", \"gradient\", \"water\", \"POI diversity\"]\n",
    "\n",
    "for i in range(len(xs)):\n",
    "    axes[i].scatter(xs[i], nodesh3[\"count\"], color=\"k\", alpha=0.1)\n",
    "\n",
    "    res = scipy.stats.linregress(xs[i], nodesh3[\"count\"])\n",
    "    axes[i].plot(\n",
    "        xs[i],\n",
    "        res.slope * xs[i] + res.intercept,\n",
    "        linewidth=2.5,\n",
    "        color=\"b\",\n",
    "    )\n",
    "\n",
    "    axes[i].set_xlabel(\n",
    "        \"Loop bits+1 (\" + xlabels[i] + \" restriction)\"\n",
    "    )  # +1 because of +1 in get_vertex_loopnums\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(\"Node density\")\n",
    "    else:\n",
    "        axes[i].set_yticklabels([])\n",
    "\n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html\n",
    "    ts = tinv(0.05, len(xs[i]) - 2)\n",
    "    print(\n",
    "        f\"slope (95%): {res.slope:.3f} +/- {ts*res.stderr:.3f}, r-value: {res.rvalue:.3f}, p-value: {res.pvalue}\"\n",
    "    )\n",
    "    print(f\"intercept (95%): {res.intercept:.3f}\" f\" +/- {ts*res.intercept_stderr:.3f}\")\n",
    "\n",
    "    # confband(xs[i], nodesh3[\"count\"], axes[i]) # The confband doesn't add much value\n",
    "    axes[i].set_ylim([0, 23])\n",
    "    axes[i].set_xlim([-1, 18])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b266d58-398a-45ec-be96-cb1e3517dce5",
   "metadata": {},
   "source": [
    "### Existing properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb2e8c8-046e-4380-b0dd-11edc0f1497f",
   "metadata": {},
   "source": [
    "#### Unweighted by length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d97e4-2e38-4438-88e7-098c000de93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfunified_properties = (\n",
    "    nodesh3.join(edges_lengthh3.drop(columns=[\"geometry\"]))\n",
    "    .join(edges_max_slopeh3.drop(columns=[\"geometry\", \"weight\"]))\n",
    "    .join(edges_has_waterh3.drop(columns=[\"geometry\", \"weight\"]))\n",
    "    .join(edges_poi_diversityh3.drop(columns=[\"geometry\", \"weight\"]))\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"count\": \"Node density\",\n",
    "            \"weight\": \"Length\",\n",
    "            \"max_slope\": \"Maximum gradient\",\n",
    "            \"has_water\": \"Has water\",\n",
    "            \"poi_diversity\": \"POI diversity\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "pd.plotting.scatter_matrix(dfunified_properties, alpha=0.05, figsize=(10, 10));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd71ab44-44c7-42fd-a835-26d8e6ad1343",
   "metadata": {},
   "source": [
    "#### Weighted by length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded6e38a-44f3-43e2-b7d0-b84693589eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfunified_properties_weighted = (\n",
    "    nodesh3.join(edges_lengthh3.drop(columns=\"geometry\"))\n",
    "    .join(edges_max_slope_wmh3.drop(columns=\"geometry\"))\n",
    "    .join(edges_has_water_wmh3.drop(columns=\"geometry\"))\n",
    "    .join(edges_poi_diversity_wmh3.drop(columns=\"geometry\"))\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"count\": \"Node density\",\n",
    "            \"weight\": \"Length\",\n",
    "            \"max_slope\": \"Maximum gradient\",\n",
    "            \"has_water\": \"Has water\",\n",
    "            \"poi_diversity\": \"POI diversity\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "pd.plotting.scatter_matrix(dfunified_properties_weighted, alpha=0.05, figsize=(10, 10));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe0d313-f2db-46a5-af02-ae9c08d99458",
   "metadata": {},
   "source": [
    "We care mostly about the first row. Visualize it better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294524fd-a0f2-47ee-a27a-6c73ab5ce27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(14, 3))\n",
    "\n",
    "y = nodesh3[\"count\"].to_list()\n",
    "xlabels = [\"Length\", \"Maximum gradient\", \"Has water\", \"POI diversity\"]\n",
    "\n",
    "nonnanmask = ~np.isnan(dfunified_properties_weighted[xlabels[3]].to_list())\n",
    "\n",
    "for i in range(len(xlabels)):\n",
    "    axes[i].scatter(\n",
    "        dfunified_properties_weighted[xlabels[i]].to_list(), y, color=\"k\", alpha=0.1\n",
    "    )\n",
    "\n",
    "    if i != 0:\n",
    "        res = scipy.stats.linregress(\n",
    "            np.array(dfunified_properties_weighted[xlabels[i]])[nonnanmask],\n",
    "            np.array(y)[nonnanmask],\n",
    "        )\n",
    "        axes[i].plot(\n",
    "            dfunified_properties_weighted[xlabels[i]],\n",
    "            res.slope * dfunified_properties_weighted[xlabels[i]] + res.intercept,\n",
    "            linewidth=2.5,\n",
    "            color=\"b\",\n",
    "        )\n",
    "        # https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html\n",
    "        ts = tinv(0.05, len(np.array(y)[nonnanmask] - 2))\n",
    "        print(\n",
    "            f\"slope (95%): {res.slope:.3f} +/- {ts*res.stderr:.3f}, r-value: {res.rvalue:.3f}, p-value: {res.pvalue}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"intercept (95%): {res.intercept:.3f}\"\n",
    "            f\" +/- {ts*res.intercept_stderr:.3f}\"\n",
    "        )\n",
    "\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(\"Node density\")\n",
    "    else:\n",
    "        axes[i].set_yticklabels([])\n",
    "    axes[i].set_xlabel(xlabels[i])\n",
    "    axes[i].set_ylim([0, 23])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e9da90-ee29-493f-a723-007f4848473f",
   "metadata": {},
   "source": [
    "### Plot all correlations together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d986894-2387-427c-a21d-4047525eb964",
   "metadata": {},
   "source": [
    "Run this notebook on all three scenarios to fully populate `dfunified_scenarios`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627ac9a8-46c9-41a1-970e-1eec233e07f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    plt.style.use(PATH[\"parameters\"] + \"plotstyle.mplstyle\")\n",
    "    dfunified_scenarios[0]\n",
    "    dfunified_scenarios[1]\n",
    "    dfunified_scenarios[2]\n",
    "\n",
    "    fig, axrows = plt.subplots(\n",
    "        nrows=4,\n",
    "        ncols=4,\n",
    "        figsize=(640 / PLOTPARAM[\"dpi\"], 480 / PLOTPARAM[\"dpi\"]),\n",
    "        dpi=PLOTPARAM[\"dpi\"],\n",
    "        squeeze=True,\n",
    "    )\n",
    "\n",
    "    rownum = 0\n",
    "    axes = axrows[rownum]\n",
    "    y = nodesh3[\"count\"].to_list()\n",
    "    xlabels = [\"Length\", \"Maximum gradient\", \"Has water\", \"POI diversity\"]\n",
    "\n",
    "    nonnanmask = ~np.isnan(dfunified_properties_weighted[xlabels[3]].to_list())\n",
    "\n",
    "    for i in range(len(xlabels)):\n",
    "        axes[i].scatter(\n",
    "            dfunified_properties_weighted[xlabels[i]].to_list(),\n",
    "            y,\n",
    "            color=\"k\",\n",
    "            alpha=0.1,\n",
    "            linewidth=0,\n",
    "        )\n",
    "\n",
    "        if i != 0:\n",
    "            res = scipy.stats.linregress(\n",
    "                np.array(dfunified_properties_weighted[xlabels[i]])[nonnanmask],\n",
    "                np.array(y)[nonnanmask],\n",
    "            )\n",
    "            axes[i].plot(\n",
    "                dfunified_properties_weighted[xlabels[i]],\n",
    "                res.slope * dfunified_properties_weighted[xlabels[i]] + res.intercept,\n",
    "                linewidth=1.5,\n",
    "                color=\"b\",\n",
    "            )\n",
    "            if res.pvalue > 0.001:\n",
    "                axes[i].text(\n",
    "                    0.96,\n",
    "                    0.95,\n",
    "                    f\"r = {res.rvalue:.2f}\\np = {res.pvalue:.2f}\",\n",
    "                    horizontalalignment=\"right\",\n",
    "                    verticalalignment=\"top\",\n",
    "                    transform=axes[i].transAxes,\n",
    "                )\n",
    "            else:\n",
    "                axes[i].text(\n",
    "                    0.96,\n",
    "                    0.95,\n",
    "                    f\"r = {res.rvalue:.2f}\",\n",
    "                    horizontalalignment=\"right\",\n",
    "                    verticalalignment=\"top\",\n",
    "                    transform=axes[i].transAxes,\n",
    "                )\n",
    "\n",
    "        if i == 0:\n",
    "            axes[i].set_ylabel(\"Node density\")\n",
    "        else:\n",
    "            axes[i].set_yticklabels([])\n",
    "        axes[i].set_xlabel(xlabels[i])\n",
    "        axes[i].set_ylim([0, 23])\n",
    "        axes[i].set_yticks([0, 5, 10, 15, 20])\n",
    "        if i == 1:  # max gradient has some outliers\n",
    "            axes[i].set_xlim([0, 20])\n",
    "        if i == 2:  # nicer xticks for water\n",
    "            axes[i].set_xticks([0, 0.25, 0.5, 0.75, 1])\n",
    "\n",
    "    for rownum in [1, 2, 3]:\n",
    "        axes = axrows[rownum]\n",
    "        sid = rownum - 1\n",
    "\n",
    "        xs = [\n",
    "            dfunified_scenarios[sid][\"Loop bits (length)\"],\n",
    "            dfunified_scenarios[sid][\"Loop bits (gradient)\"],\n",
    "            dfunified_scenarios[sid][\"Loop bits (water)\"],\n",
    "            dfunified_scenarios[sid][\"Loop bits (POI)\"],\n",
    "        ]\n",
    "        xlabels = [\"Length\", \"Gradient\", \"Water\", \"POI diversity\"]\n",
    "\n",
    "        for i in range(len(xs)):\n",
    "            axes[i].scatter(xs[i], nodesh3[\"count\"], color=\"k\", alpha=0.1, linewidth=0)\n",
    "\n",
    "            res = scipy.stats.linregress(xs[i], nodesh3[\"count\"])\n",
    "            axes[i].plot(\n",
    "                xs[i],\n",
    "                res.slope * xs[i] + res.intercept,\n",
    "                linewidth=1.5,\n",
    "                color=\"b\",\n",
    "            )\n",
    "\n",
    "            if rownum == 3:\n",
    "                axes[i].set_xlabel(\n",
    "                    \"Loop bits+1\\n\" + xlabels[i] + \" restriction\"\n",
    "                )  # +1 because of +1 in get_vertex_loopnums\n",
    "            if i == 0:\n",
    "                axes[i].set_ylabel(SCENARIO[sid][\"name_short\"] + \"\\n\\n Node density\")\n",
    "            else:\n",
    "                axes[i].set_yticklabels([])\n",
    "            if rownum == 1 or rownum == 2:\n",
    "                axes[i].set_xticklabels([])\n",
    "            axes[i].set_xticks([0, 4, 8, 12, 16])\n",
    "\n",
    "            # confband(xs[i], nodesh3[\"count\"], axes[i]) # The confband doesn't add much value\n",
    "            axes[i].set_ylim([0, 23])\n",
    "            axes[i].set_xlim([-1, 18])\n",
    "            axes[i].set_yticks([0, 5, 10, 15, 20])\n",
    "            if res.pvalue > 0.001:\n",
    "                axes[i].text(\n",
    "                    0.96,\n",
    "                    0.95,\n",
    "                    f\"r = {res.rvalue:.2f}\\np = {res.pvalue:.2f}\",\n",
    "                    horizontalalignment=\"right\",\n",
    "                    verticalalignment=\"top\",\n",
    "                    transform=axes[i].transAxes,\n",
    "                )\n",
    "            else:\n",
    "                axes[i].text(\n",
    "                    0.96,\n",
    "                    0.95,\n",
    "                    f\"r = {res.rvalue:.2f}\",\n",
    "                    horizontalalignment=\"right\",\n",
    "                    verticalalignment=\"top\",\n",
    "                    transform=axes[i].transAxes,\n",
    "                )\n",
    "\n",
    "    plt.subplots_adjust(\n",
    "        top=0.93, bottom=0.17, left=0.12, right=0.97, wspace=0.16, hspace=0.22\n",
    "    )\n",
    "\n",
    "    # Shift top row upwards\n",
    "    axes = axrows[0]\n",
    "    for i in range(len(xlabels)):\n",
    "        l, b, w, h = axes[i].get_position().bounds\n",
    "        axes[i].set_position([l, b + 0.25 * h, w, h])\n",
    "        axes[i].get_position()\n",
    "    # Shift bottom 3 rows downwards\n",
    "    for rownum in [1, 2, 3]:\n",
    "        axes = axrows[rownum]\n",
    "        for i in range(len(xlabels)):\n",
    "            l, b, w, h = axes[i].get_position().bounds\n",
    "            axes[i].set_position([l, b - 0.25 * h, w, h])\n",
    "            axes[i].get_position()\n",
    "\n",
    "    fig.savefig(\n",
    "        PATH[\"plot\"] + \"nodedensityscatter.pdf\", facecolor=\"white\", edgecolor=\"none\"\n",
    "    )\n",
    "\n",
    "except KeyError:\n",
    "    print(\"Please re-run this notebook for all scenarioids 0, 1 and 2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bikenwloops",
   "language": "python",
   "name": "bikenwloops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
